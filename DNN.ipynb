{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lossFunction as lossF\n",
    "from netLayer import netLayer\n",
    "from weightInit import weightInit\n",
    "\n",
    "class deepNeuralNetwork():\n",
    "    def __init__(self, x, y, taskMode):\n",
    "        self.x = x                                             # 2D numpy array\n",
    "        self.y = y\n",
    "        self.taskMode = taskMode                               # \"reg\", \"biC\" or \"mulC\"\n",
    "        self.numSample = self.x.shape[0]\n",
    "        \n",
    "        # WeightMatrix Initialization\n",
    "        self.initMode = \"zero\"\n",
    "        self.initDistribution = \"normal\"\n",
    "        self.initSubmode = \"inputNode\"\n",
    "        \n",
    "        self.numLayer = 0\n",
    "        self.layerSet = []\n",
    "        self.weightSet = []\n",
    "        self.biasSet = []\n",
    "        \n",
    "        self.learningRate = 0.01\n",
    "        \n",
    "        self.predictFunc = lossF.predictFunc(self.taskMode)\n",
    "        self.lossFunc = lossF.lossFunc(self.taskMode)\n",
    "        self.finalLoss = \"none\"\n",
    "        self.a = \"none\"\n",
    "            \n",
    "    def addLayer(self, layerMode, numNode, activeMode):\n",
    "        lastLayerNode = self.x.shape[1]\n",
    "        if self.numLayer != 0:\n",
    "            lastLayerNode = self.layer[self.numLayer - 1].numNode\n",
    "        \n",
    "        self.numLayer += 1\n",
    "        self.layerSet.append(netLayer(layerMode, numNode, activeMode)) \n",
    "            \n",
    "        W = weightInit(lastLayerNode, numNode, self.initMode,\n",
    "                       self.initDistribution, self.initSubmode)\n",
    "        B = np.random.normal(0, 1, (1, numNode))\n",
    "        self.weightSet.append(W)\n",
    "        self.biasSet.append(B)  \n",
    "        \n",
    "    def removeLayer(self):\n",
    "        if self.numLayer != 0:\n",
    "            self.numLayer -= 1\n",
    "            self.layerSet.pop()\n",
    "            self.weightSet.pop()\n",
    "            self.biasSet.pop()\n",
    "        else:\n",
    "            print(\"No more layer remained!\")\n",
    "        \n",
    "    def setInitMode(self, initMode, distribution=\"normal\", submode=\"inputNode\"):\n",
    "        self.initMode = initMode\n",
    "        self.distribution = distribution\n",
    "        self.submode = submode\n",
    "        \n",
    "        lastLayerNode = self.x.shape[1]\n",
    "        \n",
    "        for i in range(self.numLayer):\n",
    "            self.weightSet[i] = weightInit(lastLayerNode, self.layerSet[i].numNode, \n",
    "                                           self.initMode, self.initDistribution, self.initSubmode)\n",
    "            lastLayerNode = self.layerSet[i].numNode\n",
    "        \n",
    "    def setLearningRate(self, learningRate):\n",
    "        if (isinstance(learningRate, int) or isinstance(learningRate, float)) and learningRate > 0:\n",
    "            self.learningRate = learningRate\n",
    "        else:\n",
    "            print(\"Illegal learning rate!\")\n",
    "        \n",
    "    def forward(self):\n",
    "        self.layerOutputSet = []\n",
    "        self.layerActivatedOutputSet = []\n",
    "        \n",
    "        layerInput = self.x\n",
    "        \n",
    "        for i in range(self.numLayer):\n",
    "            layerOutput = np.dot(layerInput, self.weightSet[i]) + self.biasSet[i]\n",
    "            self.layerOutputSet.append(layerOutput)\n",
    "            activatedOutput = self.layerSet[i].activeFunc(layerOutput)\n",
    "            self.layerActivatedOutputSet.append(activatedOutput)\n",
    "            layerInput = activatedOutput\n",
    "        \n",
    "        self.a = self.predictFunc(layerInput)\n",
    "        self.loss = self.lossFunc(self.a, self.y)\n",
    "        self.finalLoss = np.sum(self.loss)\n",
    "        \n",
    "    def backPropagation(self):\n",
    "        self.layerGradOutput = []\n",
    "        self.layerGradW = []\n",
    "        self.layerGradB = []\n",
    "        \n",
    "        gradZ = self.a - self.y\n",
    "        \n",
    "        for i in range(self.numLayer-1, -1, -1):\n",
    "            X = self.layerActivatedOutputSet[i-1]\n",
    "            if i == 0:\n",
    "                X = self.x\n",
    "            self.layerGradOutput.insert(0, gradZ)\n",
    "            self.layerGradW.insert(0, np.dot(X.T, gradZ))\n",
    "            self.layerGradB.insert(0, np.dot(np.ones((1, self.numSample)), gradZ))\n",
    "            if i > 0:\n",
    "                gradA = np.dot(gradZ, W.T)\n",
    "                gradZ = gradA * self.layerSet[i-1].gradActive(self.layerOutputSet[i-1])\n",
    "        \n",
    "        for i in range(self.numLayer):\n",
    "            self.weightSet[i] -= self.learningRate * self.layerGradW[i]\n",
    "            self.biasSet[i] -= self.learningRate * self.layerGradB[i]\n",
    "            \n",
    "    def train(self, eps):\n",
    "        cnt = 0\n",
    "        while cnt < 10000:\n",
    "            self.forward()\n",
    "            if self.finalLoss < eps:\n",
    "                break\n",
    "            self.backPropagation()\n",
    "            cnt += 1\n",
    "            \n",
    "    def getResult(self):\n",
    "        print(self.weightSet)\n",
    "        print(self.biasSet)\n",
    "        print(self.finalLoss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4492,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(-10, 10, (100, 2))\n",
    "W = np.array([[2],[-1]])\n",
    "B = np.array([[1]])\n",
    "Y = np.dot(X, W) + B + np.random.normal(0, 1, (100, 1))\n",
    "net = deepNeuralNetwork(X, Y, \"reg\")\n",
    "net.addLayer(\"FC\", 1, \"none\")\n",
    "net.setInitMode(\"Xavier\")\n",
    "net.setLearningRate(5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.97953368],\n",
      "       [-1.01151764]])]\n",
      "[array([[0.88490848]])]\n",
      "47.366815817297066\n"
     ]
    }
   ],
   "source": [
    "net.train(10)\n",
    "net.getResult()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
